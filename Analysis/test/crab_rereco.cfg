#
# Re-run HLT for skimming CRAFT 09 data 
#

[CRAB]

jobtype = cmssw
scheduler = glitecoll
### NOTE: just setting the name of the server (pi, lnl etc etc ) 
###       crab will submit the jobs to the server...   
#server_name = bari

[CMSSW]

### The data you want to access (to be found on DBS)

# CRAFT 09 HLT re-skim
dbs_url = http://cmsdbsprod.cern.ch/cms_dbs_ph_analysis_02/servlet/DBSServlet
datasetpath=/Calo/jbrooke-StoppedHSCP_CRAFT09_rerunHLT_v5-a9f20537e9e1239e6910ee9cb81f358d/USER

# collisions raw data
#datasetpath=/MinimumBias/BeamCommissioning09-v1/RAW
#runselection=124022,124023,124024,124025,124026,124027,124029,124030

# beam test
#datasetpath=/ZeroBias/BeamCommissioning09-PromptReco-v2/RECO
#runselection=123615

# CRAFT 09
#datasetpath=/Calo/CRAFT09-GR09_31X_V5P_StoppedHSCP-332_v4/RAW-RECO
#runselection=110958,110972,110987,110998,111009,111039,111138

# CRAFT 08
#datasetpath=/Calo/Commissioning08-v1/RAW
#runselection=68021

#datasetpath=None

### The ParameterSet you want to use
pset=rereco_jan29th.py

### Splitting parameters
total_number_of_events=-1
events_per_job = 100000
#number_of_jobs = -1

### The output files (comma separated list)
get_edm_output = 1
	
[USER]

ui_working_dir = StoppedHSCP_CRAFT09_ReRecoJan29th_v1

### OUTPUT files Management
##  output back into UI 
return_data = 0

### OUTPUT files INTO A SE
copy_data = 1
storage_element          = T2_UK_SGrid_RALPP
#user_remote_dir          = StoppedHSCP_CRAFT09_ReRecoJan29th_v1

# DBS publication
publish_data = 1
publish_data_name = StoppedHSCP_CRAFT09_rereco_v4
dbs_url_for_publication = https://cmsdbsprod.cern.ch:8443/cms_dbs_ph_analysis_02_writer/servlet/DBSServlet


#if server 
#thresholdLevel = 50
#eMail = jim.brooke@cern.ch

[GRID]

## RB/WMS management:
rb = CERN
proxy_server = myproxy.cern.ch

##  Black and White Lists management:
## By Storage
#se_black_list = 
#se_white_list = 

## By ComputingElement 
#ce_black_list =
#ce_white_list = 
#ce_white_list = lcgce03.phy.bris.ac.uk, lcgce02.phy.bris.ac.uk, lcgce01.phy.bris.ac.uk 

[CONDORG]

# Set this to condor to override the batchsystem defined in gridcat.
#batchsystem = condor

# Specify addition condor_g requirments
# use this requirment to run on a cms dedicated hardare
# globus_rsl = (condor_submit=(requirements 'ClusterName == \"CMS\" && (Arch == \"INTEL\" || Arch == \"X86_64\")'))
# use this requirement to run on the new hardware
#globus_rsl = (condor_submit=(requirements 'regexp(\"cms-*\",Machine)'))

